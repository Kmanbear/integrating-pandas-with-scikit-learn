{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from mymetrics import root_mean_squared_log_error\n",
    "\n",
    "hs = pd.read_csv('data/housing_sample.csv')\n",
    "X = hs[['GrLivArea']].values\n",
    "y = hs.pop('SalePrice').values\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "cross_val_score(lr, X, y, cv=kf, scoring=root_mean_squared_log_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "You can change the 'specifications' of how an estimator is constructed during instantiation (step 2). These specifications are called **hyperparameters** and once set during instantiation are not changed. They differ from **model parameters** which are learned during training (step 3). Using different values for these hyperparameters can lead to drastically different results.\n",
    "\n",
    "Linear regression does not have many hyperparameters, so in this notebook we will work with decision trees instead, which have many more. Common hyperparameters that are often set for decision trees are `max_depth` (the maximum depth of a tree) and `min_samples_split` (the minimum number of samples a node must contain for a split to be possible.\n",
    "\n",
    "### Default hyperparameter values\n",
    "\n",
    "All estimators provide default values for these hyperparameters which is why you can instantiate them without setting them explicitly. Let's construct our first decision tree estimator with the default values. The defaults are `None` for both `max_depth` and `min_samples_split`. There are several other hyperparameters that also have default values, but we will not inspect them. We will also use a couple more input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hs[['YearBuilt', 'GrLivArea', 'GarageArea']].values\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and instantiate the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of fitting the model directly with the `fit` method, we can go straight to cross validation which fits a new model for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "scores = cross_val_score(dtr, X, y, cv=kf, scoring=root_mean_squared_log_error)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the mean of the cross validated scores to get a single overall performance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select new hyperparameters\n",
    "Let's instantiate our decision tree with a different set of hyperparameters by setting `max_depth` to 4 and a `min_samples_split` to 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=5, min_samples_split=50)\n",
    "scores = cross_val_score(dtr, X, y, cv=kf, scoring=root_mean_squared_log_error)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search many hyperparameter combinations with `GridSearchCV`\n",
    "The second set of hyperparameters from above returned a better score than the defaults. To help find the best combination of hyperparameters, use `GridSearchCV` from the `model_selection` module. To work with it, you must first create a **parameter grid** mapping the parameter name as a string to the possible values you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'max_depth': range(2, 11), 'min_samples_split': [5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-step process for `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` is a meta-estimator or an estimator that fits other estimators. It follows the same three-step process as the other estimators, but must be instantiated with the estimator you would like to search and the parameter grid. It also does cross validation and has the same `cv` and `scoring` parameters as `cross_val_score` which can also be set during instantiation.\n",
    "\n",
    "During the `fit` method, every single combination of hyperparameters is scored with cross validation. So, in our specific example, we have 9 possible values for `max_depth` and 5 for `min_samples_split` leading to 45 different combinations of hyperparameters. Each of these combinations will have a mean cross validated score which will be used to rank the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dtr = DecisionTreeRegressor()\n",
    "gs = GridSearchCV(estimator=dtr, param_grid=grid, cv=kf, scoring=root_mean_squared_log_error)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the best combination\n",
    "\n",
    "The best combination of hyperparameters is found with the `best_params_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "The results are contained in the `cv_results_` attribute which is a large dictionary that can be converted to a DataFrame for easier interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(gs.cv_results_)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have exactly two hyperparameters you can pivot them into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.pivot('param_max_depth', 'param_min_samples_split', 'mean_test_score').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the best model\n",
    "The best model is saved to the `best_estimator_` attribute. You can now use this to make future predictions. It's a decision tree trained on all the data with the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from mymetrics import root_mean_squared_log_error\n",
    "\n",
    "hs = pd.read_csv('data/housing_sample.csv')\n",
    "X = hs[['YearBuilt', 'GrLivArea', 'GarageArea']].values\n",
    "y = hs.pop('SalePrice').values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "grid = {'max_depth': range(2, 11), 'min_samples_split': [5, 10, 20, 50, 100]}\n",
    "gs = GridSearchCV(estimator=dtr, param_grid=grid, cv=kf, scoring=root_mean_squared_log_error)\n",
    "gs.fit(X, y)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(gs.cv_results_)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Practice using `GridSearchCV` with different combinations of hyperparameters using different regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
