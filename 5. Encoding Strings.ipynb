{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Encoding Strings\n",
    "\n",
    "## Summary of Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from mymetrics import root_mean_squared_log_error\n",
    "\n",
    "hs = pd.read_csv('data/housing_sample.csv')\n",
    "X = hs[['YearBuilt', 'GrLivArea', 'GarageArea', 'LotFrontage']].values\n",
    "y = hs.pop('SalePrice').values\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "si = SimpleImputer(strategy='mean')\n",
    "ss = StandardScaler()\n",
    "ridge = Ridge()\n",
    "\n",
    "steps = [('impute', si), ('standardize', ss), ('ridge', ridge)]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "grid = {'impute__strategy': ['mean', 'median'],\n",
    "        'ridge__alpha': np.logspace(-5, 5)}\n",
    "gs = GridSearchCV(estimator=pipe, param_grid=grid, \n",
    "                  cv=kf, scoring=root_mean_squared_log_error)\n",
    "gs.fit(X, y)\n",
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String vs Numeric columns\n",
    "Thus far, we haven't looked at any of the string columns. This is because string columns are not allowed to be passed into machine learning estimators in scikit-learn. They must be encoded to numeric first. Two common ways of encoding strings to numeric are one-hot and ordinal. \n",
    "\n",
    "### One-hot encoding\n",
    "One-hot encoding is useful whenever there is no inherent order of the string values such as we see in the neighborhood column. The `OneHotEncoding` transformer is found in the `preprocessing` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big upgrade to `OneHotEncoder` in 0.20\n",
    "The `OneHotEncoder` was given a huge upgrade in version 0.20. Previously it was only able to handle numeric values.\n",
    "\n",
    "### Using `OneHotEncoder`\n",
    "It transforms each column into several new columns where the number of new columns is equal to the number of unique values in the original column. Each row will contain all 0's except for the a single column, which will be 1, to represent that string. Let's see an example of how it works with dummy data. Note that we must instantiate it with `sparse` set to `False` in order to get a visualize the array on our screens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([['chevy'], ['ford'], ['chevy'], ['chrysler'], ['mercedes']])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn provides the method `get_feature_names` to get the name of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values not in the training set\n",
    "If you wish to use this same encoding to transform another column, an error will be raised if one of the values did not appear in the training set as happens below with 'toyota'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([['ford'], ['chrysler'], ['toyota']])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(b) # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Unknown\n",
    "As a workaround, you can instantiate `OneHotEncoder` by setting `handle_unknown` to 'ignore'. The unknown value will be encoded as a row of all 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe.fit_transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last row is encoded as all 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode the housing dataset\n",
    "Let's use the `OneHotEncoder` on both of the string columns in our dataset. To do so we will need to fill in the missing values and do so with the string 'MISSING'. We use a pipeline with the `SimpleImputer` to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hs[['Neighborhood', 'Exterior1st']].values\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "si = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "steps = [('impute', si), ('encode', ohe)]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "X1 = pipe.fit_transform(X)\n",
    "X1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['encode'].get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Read in the housing_original.csv file to get the full housing dataset with many more variables. Select a subset of the string variables to encode. Use a pipeline to fill missing values if need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra - OrdinalEncoder\n",
    "A different encoding strategy is to use a single column and encode each string with a different number beginning at 0. This makes sense if the strings have a natural ordering such as descriptive feedback ratings (very bad, bad, neutral, good, very good) or the color of a diamond. If there is no natural ordering then this method would arbitrarily rank one string greater than another.\n",
    "\n",
    "Below is a simple example with some dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([['good'], ['very good'], ['good'], ['bad'], ['very bad']], dtype='object')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder(categories=[['very bad', 'bad','neutral', 'good', 'very good']])\n",
    "oe.fit_transform(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
