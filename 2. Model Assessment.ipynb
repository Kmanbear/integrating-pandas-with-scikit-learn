{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Assessment\n",
    "\n",
    "## Summary of commands\n",
    "Code from the previous notebook is summarized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hs = pd.read_csv('data/housing_sample.csv')\n",
    "X = hs[['GrLivArea']].values\n",
    "y = hs.pop('SalePrice').values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  # step 1 - import\n",
    "lr = LinearRegression()                            # step 2 - instantiate\n",
    "lr.fit(X, y)                                       # step 3 - fit\n",
    "\n",
    "lr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model performance\n",
    "All supervised estimators have a `score` method that will accept input data and the target variable and return a metric to evaluate model performance. By default, scikit-learn uses R-squared to assess model performance for regressors. R-squared is a relative metric that returns the percentage of the total variance eliminated from the input. A score of 1 means that input data is perfectly mapped to its output. It is the highest possible score. Let's calculate this now on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root mean squared error of logged sale price\n",
    "Kaggle uses a different metric to evaluate the model than R-squared. It uses the [root mean squared error][1] of the logged sale price. This is an absolute metric with 0 being the best possible result (no error). It is isn't possible to use the `score` method to calculate this. The `metrics` module contains [many scoring metrics for regressors][2] such as the `mean_squared_log_error` function which is very close to what we need.\n",
    "\n",
    "The scoring functions are used differently than the `score` method. You must pass it the actual ('true') output values and their corresponding predicted values.\n",
    " \n",
    "[1]: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation\n",
    "[2]: https://scikit-learn.org/stable/modules/classes.html#regression-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "y_pred = lr.predict(X)\n",
    "mean_squared_log_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the square root results in the exact error metric that Kaggle uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sqrt(mean_squared_log_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own scoring function\n",
    "Let's write a function that calculates the root mean squared error of the logged sale price and verify that the result is the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "# test\n",
    "rmsle(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a formal scikit-learn scorer\n",
    "scikit-learn has a function in the `metrics` module called `make_scorer`. It will turn your user-defined metric into a formal scikit-learn 'scorer'. The reason you'd want to do this is so that your custom metric can be used during hyper-parameter tuning when grid searching with `GridSearchCV`.\n",
    "\n",
    "To create the scorer, pass the `make_scorer` function your custom function. Additionally, if the metric is defined such that a lower score is better, as is the case with root mean squared error, then you need to set the parameter `greater_is_better` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "root_mean_squared_log_error = make_scorer(rmsle, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new object takes the estimator, the input data, and the output data as arguments. Note, that you do not pass it the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_log_error(lr, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does it return the negative of the metric?\n",
    "It returns the negative of our previous score so that scikit-learn can have a consistent way of ranking models with a higher score being better.\n",
    "\n",
    "## Cross Validation\n",
    "Assessing model performance using the data that the model was trained gives misleading results. For a more accurate assessment, we can use cross validation to train on one subset of the data and test on an unseen subset. The `cross_val_score` function from the `model_selection` module will automate this procedure for us.\n",
    "\n",
    "We must pass `cross_val_score` our estimator, input data, and output data. You can also set the number of folds with the `cv` parameter. By default, it performs K-fold cross validation, where K is equal to 3 (but this is changing to 5 in version 0.22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use our custom scorer\n",
    "By default, `cross_val_score` returns R-squared values for regressors. Set the `scoring` parameter to the scorer we created above to get root mean squared log error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X, y, cv=5, scoring=root_mean_squared_log_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place custom scorer in a module\n",
    "Take a look at the metrics.py module. It contains the definition for `root_mean_squared_log_error` which can be imported directly now from there in all the other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a specific flavor of cross validation\n",
    "scikit-learn offers a [variety of different 'splitters'][1] in the `model_selection` module to perform cross validation. These splitters have different strategies for cross validation with several allowing you to shuffle the data which does not happen by default. The splitters are classes that must be instantiated. Here we create a splitter instance that does 5 splits and shuffles the data.\n",
    "\n",
    "[1]: https://scikit-learn.org/stable/modules/classes.html#splitter-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this splitter to the `cv` parameter of `cross_val_score`. You will get different scores each time you run this as the data is getting shuffled randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X, y, cv=kf, scoring=root_mean_squared_log_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = pd.read_csv('data/housing_sample.csv')\n",
    "X = hs[['GrLivArea']].values\n",
    "y = hs.pop('SalePrice').values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  # step 1 - import\n",
    "lr = LinearRegression()                            # step 2 - instantiate\n",
    "lr.fit(X, y)                                       # step 3 - fit\n",
    "\n",
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "root_mean_squared_log_error = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "cross_val_score(lr, X, y, cv=kf, scoring=root_mean_squared_log_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Repeat cross validation using our custom scorer on several of the other regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra - more on custom scorer\n",
    "It isn't necessary to use the `make_scorer` function. You can instead create a function that accepts the estimator, input data, and target variable. Just make sure to return the negative of the score if a lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_scorer(est, X, y):\n",
    "    y_pred = est.predict(X)\n",
    "    return -np.sqrt(mean_squared_log_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_scorer(lr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(lr, X, y, cv=kf, scoring=rmsle_scorer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
